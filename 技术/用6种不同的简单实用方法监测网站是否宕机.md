# 用6种不同的简单实用方法监测网站是否宕机

### 使用 fping 命令检测
fping 命令 是一个类似 ping 的程序，使用互联网控制消息协议（ICMP）的回应请求报文来判断目标主机是否能回应。fping 与 ping 的不同之处在于它可以并行地 ping 任意数量的主机，也可以从一个文本文件读入主机名称。fping 发送一个 ICMP 回应请求后不等待目标主机响应，就以轮询模式向下一个目标主机发请求。如果一个目标主机有响应，那么它就被标记为存活的，然后从检查目标列表里去掉。如果一个目标主机在限定的时间和（或）重试次数内没有响应，则被指定为网站无法到达的。

	# 命令
	fping www.google.com www.twitter.com
	# 结果输出
	www.google.com is alive
	www.twitter.com is alive

### 使用 http 命令检测
HTTPie 是一个命令行HTTP客户端。httpie是一个可以与web服务通过CLI 进行交互的现代工具。httpie工具提供了简单的http命令，可以通过发送简单的、自然语言语法的任意HTTP请求得到多彩的结果输出。HTTPie可以用来对 HTTP 服务器进行测试、调试和基本的交互。

	# 命令
	http 2daygeek.com
	# 结果输出
	HTTP/1.1 301 Moved Permanently
	CF-RAY: 5476000f58a8ecd7-DFW
	Cache-Control: max-age=3600
	Connection: keep-alive
	Date: Thu, 19 Dec 2019 02:38:25 GMT
	Expires: Thu, 19 Dec 2019 03:38:25 GMT
	Location: https://2daygeek.com/
	Server: cloudflare
	Transfer-Encoding: chunked
	Vary: Accept-Encoding

### 使用 curl 命令检测
curl命令是一个用于在服务器间通过支持的协议（DICT、FILE、FTP、FTPS、GOPHER、HTTP、HTTPS、IMAP、IMAPS、LDAP、LDAPS、POP3、POP3S、RTMP、RTSP、SCP、SFTP、SMTP、SMTPS、TELNET 和 TFTP）传输数据的工具。这个工具不支持用户交互。curl 也支持使用代理、用户认证、FTP 上传、HTTP POST 请求、SSL 连接、cookie、断点续传、Metalink 等等。curl由 libcurl 库提供所有与传输有关的能力。

	# 命令
	curl -I https://www.facebook.com/

	# 结果输出
	HTTP/1.1 200 OK
	Set-Cookie: fr=1En2kNml7n1DnO3Hy..Bd-uOO.Aq.AAA.0.0.Bd-uOO.AWVCo1q_; expires=Wed, 18-Mar-2020 02:42:21 GMT; Max-Age=7775999; path=/; domain=.facebook.com; secure; httponly
	Set-Cookie: sb=juP6Xco8NKkEe6e4TNdgprUc; expires=Sat, 18-Dec-2021 02:42:22 GMT; Max-Age=63072000; path=/; domain=.facebook.com; secure; httponly
	Cache-Control: private, no-cache, no-store, must-revalidate
	Pragma: no-cache
	Strict-Transport-Security: max-age=15552000; preload
	Vary: Accept-Encoding
	X-Content-Type-Options: nosniff
	X-Frame-Options: DENY
	X-XSS-Protection: 0
	Expires: Sat, 01 Jan 2000 00:00:00 GMT
	Content-Type: text/html; charset="utf-8"
	X-FB-Debug: Rs0kfHfeM2pGL7FiZzU8wwM0UimkLisEs6Pasos/z+MOkiMGuqkpnPlas0r+wCm6AdeUk8zAxmcHSyxLb+GLHw==
	Date: Thu, 19 Dec 2019 02:42:23 GMT
	Transfer-Encoding: chunked
	Alt-Svc: h3-24=":443"; ma=3600
	Connection: keep-alive


	# 只检测HTTP状态命令
	curl -I https://www.facebook.com/ 2>&1 | awk '/HTTP\// {print $2}'
	# 结果输出
	200

### 使用 wget 命令检测
wget命令（前身是Geturl）是一个自由开源的命令行下载工具，通过 HTTP、HTTPS、FTP 和其他广泛使用的互联网协议获取文件。wget 是非交互式的命令行工具，由 World Wide Web 和 get 得名。wget 相对于其他工具来说更优秀，功能包括后台运行、递归下载、多文件下载、断点续传、非交互式下载和大文件下载。
	# 命令
	wget -S --spider https://www.facebook.com/

	# 输出结果
	Spider mode enabled. Check if remote file exists.
	--2019-12-19 03:49:21--  https://www.facebook.com/
	Resolving www.facebook.com (www.facebook.com)... 2a03:2880:f134:183:face:b00c:0:25de, 31.13.93.35
	Connecting to www.facebook.com (www.facebook.com)|2a03:2880:f134:183:face:b00c:0:25de|:443... connected.
	HTTP request sent, awaiting response... 
	  HTTP/1.1 302 Found
	  Location: https://www.facebook.com/unsupportedbrowser
	  Strict-Transport-Security: max-age=15552000; preload
	  Content-Type: text/html; charset="utf-8"
	  X-FB-Debug: 4baGbXkBOXWgHPVAXSUtnlcO+bxVeeV92tlfYxGIxOWJXF1yMnBZCSJFjHFyRJ8M1E19D8Xt/hXSKjX+VhA4nA==
	  Date: Thu, 19 Dec 2019 03:49:24 GMT
	  Alt-Svc: h3-24=":443"; ma=3600
	  Connection: keep-alive
	  Content-Length: 0
	Location: https://www.facebook.com/unsupportedbrowser [following]
	Spider mode enabled. Check if remote file exists.
	--2019-12-19 03:49:21--  https://www.facebook.com/unsupportedbrowser
	Connecting to www.facebook.com (www.facebook.com)|2a03:2880:f134:183:face:b00c:0:25de|:443... connected.
	HTTP request sent, awaiting response... 
	  HTTP/1.1 200 OK
	  Cache-Control: private, no-cache, no-store, must-revalidate
	  Pragma: no-cache
	  Strict-Transport-Security: max-age=15552000; preload
	  Vary: Accept-Encoding
	  X-Content-Type-Options: nosniff
	  X-Frame-Options: DENY
	  X-XSS-Protection: 0
	  Expires: Sat, 01 Jan 2000 00:00:00 GMT
	  Content-Type: text/html; charset="utf-8"
	  X-FB-Debug: zBMymFshuHVSnrsLYx1YP2wUVggTeR4z9+ZIcvVrPk12A8djdLFnJpHV0n81T/W7rQxKRMOS5S5CA/GFwpCSOw==
	  Date: Thu, 19 Dec 2019 03:49:24 GMT
	  Transfer-Encoding: chunked
	  Alt-Svc: h3-24=":443"; ma=3600
	  Connection: keep-alive
	Length: unspecified [text/html]
	Remote file exists and could contain further links,
	but recursion is disabled -- not retrieving.

	# 只检测HTTP状态
	wget --spider -S "https://www.facebook.com" 2>&1 | awk '/HTTP\// {print $2}'	

### 使用 lynx 命令检测
lynx 是一个在可寻址光标字符单元终端上使用的基于文本的高度可配的 web 浏览器，它是最古老的 web 浏览器并且现在仍在活跃开发。
	# 命令
	lynx -head -dump https://www.facebook.com/

	# 结果输出
	HTTP/1.1 302 Found
	Vary: Accept-Encoding
	Location: https://www.facebook.com/unsupportedbrowser
	Strict-Transport-Security: max-age=15552000; preload
	Content-Type: text/html; charset="utf-8"
	X-FB-Debug: WzVFh2gLEUcyT4UwlDOFNz+XOS7ZN5wRJTWBEsMc0nalW3GajZ+ZEzc0VEhjOW3LFE/Z
	ll0Zfl6nP9hvnN4uOA==
	Date: Thu, 19 Dec 2019 03:54:18 GMT
	Alt-Svc: h3-24=":443"; ma=3600
	Connection: close
	Content-Length: 0

	# 只检测HTTP状态
	lynx -head -dump https://www.facebook.com/ 2>&1 | awk '/HTTP\// {print $2}'
	# 结果输出
	302

### 使用telnet命令
telnet 命令是一个使用 TELNET 协议用于 TCP/IP 网络中多个主机相互通信的古老的网络协议。它通过 23 端口连接其他设备如计算机和网络设备。telnet 是不安全的协议，现在由于用这个协议发送的数据没有经过加密可能被黑客拦截，所以不推荐使用。大家都使用经过加密且非常安全的 SSH 协议来代替 telnet。
	# 命令
	telnet facebook.com 80

	# 结果输出
	Trying 2a03:2880:f134:183:face:b00c:0:25de...
	Connected to facebook.com.
	Escape character is '^]'.
	GET /
	HTTP/1.1 301 Moved Permanently
	Vary: Accept-Encoding
	Location: http://www.facebook.com/
	Content-Type: text/html; charset="utf-8"
	X-FB-Debug: T4sUuW5aFbcwi12VmFCqc0rmN6JexuT2k+MDbHzSk4ExwMoKOfqNllpzqKH3c1jdKXv/K/CCqPBbHLhaxMhICQ==
	Date: Thu, 19 Dec 2019 03:58:06 GMT
	Alt-Svc: h3-24=":443"; ma=3600
	Connection: close
	Content-Length: 0

	Connection closed by foreign host.

以上就是一些简单检测网站是否alive的命令，每个命令都根据特定业务写成脚本并自动化，以下结合curl命令给出一个简单的shell脚本:
	#!/bin/bash
	# -----------------------------------------------------------------------------------------------
	# Filename: check-site-alive.sh
	# Version: 0.0.1
	# Date: 2019/12/19
	# Author: Zhang Zhao <netewolf103@gmail.com>
	# Description: Detect if a website is online.
	# -----------------------------------------------------------------------------------------------

	printDelimiter() {
	    echo "----------------------------------"
	}

	for SITE in $*; do
	    HTTP_STATUS=`curl -I "$SITE" 2>&1 | awk '/HTTP\// {print $2}'`
	    
	    case "$HTTP_STATUS" in
	        200|301|204|302)
	            echo "$SITE is alive"
	        ;;

	        *)
	            echo "$SITE is offline, HTTP STATUS: $HTTP_STATUS"
	        ;;
	    esac

	    printDelimiter
	done

	exit $?